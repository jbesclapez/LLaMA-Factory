services:
  llamafactory:
    build:
      dockerfile: ./docker/docker-cuda/Dockerfile
      context: ../..
      args:
        INSTALL_BNB: false
        INSTALL_VLLM: false
        INSTALL_DEEPSPEED: false
        INSTALL_FLASHATTN: false
        PIP_INDEX: https://pypi.org/simple
    container_name: llamafactory
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}  # Do not forget to add the token in your environemetn variable
    volumes:
      - /home/aiqos/Documents/Docker/llamafactory/hf_cache:/root/.cache/huggingface
      - /home/aiqos/Documents/Docker/llamafactory/ms_cache:/root/.cache/modelscope
      - /home/aiqos/Documents/Docker/llamafactory/data:/app/data
      - /home/aiqos/Documents/Docker/llamafactory/output:/app/output
      - /home/aiqos/Documents/Docker/llamafactory/saves:/app/saves
      - /home/aiqos/Documents/Docker/llamafactory/exports:/app/exports
    ports:
      - "7860:7860"
      - "8000:8000"
    ipc: host
    tty: true
    stdin_open: true
    command: ["llamafactory-cli", "webui"]
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: "all"
            capabilities: [gpu]
    restart: unless-stopped
